{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pathlib import Path\nimport sys\nimport os\nBASE_PATH = Path('/kaggle/input/tweet-dataset/')\nprint(sys.path)\nsys.path.append('/kaggle/input/tweet-dataset/')\nsys.path.append('/kaggle/input/bertClassifier-ckpt/')\nsys.path.append('/kaggle/input/notebook9c29aaf992/')\nprint(sys.path)\nos.environ[\"WANDB_API_KEY\"] = '9583728ef6ed77991e73653a08b4ee2d328b1fd9'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nimport pytorch_lightning as pl\nfrom torch.utils.data import Dataset, DataLoader\nimport wandb\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom datetime import timedelta\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport nltk\ndler = nltk.downloader.Downloader()\ndler._update_index()\nnltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('omw-1.4')\nimport helpers as hlp\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\nfrom transformers import (\n    AutoTokenizer, AutoModelForSequenceClassification,\n    TrainingArguments, Trainer, DataCollatorWithPadding,\n    AutoModel\n)\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\nfor device_nb in range(torch.cuda.device_count()):\n    torch.cuda.set_device(device_nb)\n    print(torch.cuda.get_device_name(), device_nb)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-17T19:56:03.352956Z","iopub.execute_input":"2022-12-17T19:56:03.353619Z","iopub.status.idle":"2022-12-17T19:56:23.156466Z","shell.execute_reply.started":"2022-12-17T19:56:03.353566Z","shell.execute_reply":"2022-12-17T19:56:23.155314Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data] Downloading package words to /usr/share/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n","output_type":"stream"},{"name":"stdout","text":"Tesla T4 0\nTesla T4 1\n","output_type":"stream"}]},{"cell_type":"code","source":"print(20*'-','loading data', 20*'-')\nt_pos = pd.read_table(BASE_PATH / \"train_pos_full.txt\", header=None, names=['tweet'], dtype=str,on_bad_lines='skip')\nt_pos['label'] = 1\nt_neg = pd.read_table(BASE_PATH /\"train_neg_full.txt\", header=None, names=['tweet'], dtype=str,on_bad_lines='skip')\nt_neg['label'] = 0\ndf = pd.concat((t_pos,t_neg), ignore_index=True)\nprint(20*'-','preprocessing data', 20*'-')\n#df['tweet'] = df['tweet'].apply(lambda x: hlp.remove_stopwords(x))\n#df['tweet'] = df['tweet'].apply(lambda x: hlp.remove_punct(x))\ndf['tweet'] = df['tweet'].apply(lambda x: hlp.add_space(x))\ndf['tweet'] = df['tweet'].apply(lambda x: hlp.remove_white_space(x))\n#df['tweet'] = df['tweet'].apply(lambda x: hlp.remove_words_digits(x))\ndf['tweet'] = df['tweet'].apply(lambda x: hlp.to_lower(x))\n#df['tweet'] = df['tweet'].apply(lambda x: hlp.remove_specific_words(x))\ndf['tweet'] = df['tweet'].apply(lambda x: hlp.remove_repeating_char(x))\n#df['tweet'] = df['tweet'].apply(lambda x: hlp.remove_single_char(x))\ndf['tweet'] = df['tweet'].apply(lambda x: hlp.unslang(x))\ndf['tweet'] = df['tweet'].apply(lambda x: hlp.lemmatize(x))\ntrain_df, val_df = train_test_split(df,test_size=.025,random_state=42)\nprint(train_df.shape,val_df.shape)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-17T19:56:23.159875Z","iopub.execute_input":"2022-12-17T19:56:23.160902Z","iopub.status.idle":"2022-12-17T20:00:01.667094Z","shell.execute_reply.started":"2022-12-17T19:56:23.160858Z","shell.execute_reply":"2022-12-17T20:00:01.666057Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"-------------------- loading data --------------------\n-------------------- preprocessing data --------------------\n(2396839, 2) (61458, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"class TweetDataset(Dataset):\n  \"\"\"\n  torch dataset class specific for our project\n  \"\"\"\n  def __init__(self,tweets_df, tokenizer, max_len):\n    super().__init__()\n    self.tweets = tweets_df.tweet.to_numpy()\n    self.targets = tweets_df.label.to_numpy()\n    self.tokenizer = tokenizer\n    self.max_len = max_len\n  \n  def __len__(self):\n    return len(self.tweets)\n  \n  def __getitem__(self, item):\n    \"\"\"\n    encodes the input with the bert tokenizer\n    \"\"\"\n    tweets = str(self.tweets[item])\n    targets = self.targets[item]\n    encoding = self.tokenizer.encode_plus(\n      tweets,\n      add_special_tokens=True,\n      max_length=self.max_len,\n      #padding=True,\n      #truncation=True,\n      return_token_type_ids=False,\n      pad_to_max_length=True,\n      return_attention_mask=True,\n      return_tensors='pt',\n    )\n    return {\n      'tweet_text': tweets,\n      'input_ids': encoding['input_ids'].flatten(),\n      'attention_mask': encoding['attention_mask'].flatten(),\n      'targets': torch.tensor(targets, dtype=torch.long)\n    }\n  \nclass TweetDataModule(pl.LightningDataModule):\n\n  def __init__(self,train_dataset, val_dataset, batch_size=8):\n    super().__init__()\n    self.train_dataset = train_dataset\n    self.val_dataset = val_dataset\n    self.batch_size = batch_size\n\n  def train_dataloader(self):\n      return DataLoader(self.train_dataset,self.batch_size)\n\n  def val_dataloader(self):\n      return DataLoader(self.val_dataset, self.batch_size)\n\n\nclass SentimentClassifier(pl.LightningModule):\n  \"\"\"\n  Sentiment classifier model. adds a feed-forward NN to bert-base-uncased.\n  \"\"\"\n  def __init__(self, model_name, lr = 2e-5, adam_eps=1e-8, weight_decay=0., warmup_steps=0, freeze_bert=False):\n    super(SentimentClassifier, self).__init__()\n    self.save_hyperparameters()\n    self.bert = BertModel.from_pretrained(model_name)\n    if freeze_bert:\n        self.bert.eval()\n            # freeze params\n        for param in self.bert.parameters():\n                param.requires_grad = False\n\n    self.drop = nn.Dropout(p=0.3)\n    self.out = nn.Linear(self.bert.config.hidden_size, 2)\n    self.loss_fn = nn.CrossEntropyLoss()\n    self.lr = lr\n    self.adam_eps = adam_eps\n    self.warmup_steps = warmup_steps\n    self.freeze_bert = freeze_bert\n    \n  def forward(self, input_ids, attention_mask):\n        \n    pooled_output = self.bert(\n      input_ids=input_ids,\n      attention_mask=attention_mask\n    )[1]\n    output = self.drop(pooled_output)\n    return F.softmax(self.out(output), dim=1)\n\n  def training_step(self, batch, batch_idx):\n      input_ids = batch['input_ids']\n      attention_mask = batch['attention_mask']\n      targets = batch['targets']\n      logits = self.forward(input_ids,attention_mask)\n\n      loss = self.loss_fn(logits,targets)\n      self.log('train/loss', loss)\n      return loss\n\n  def validation_step(self, batch, batch_idx):\n      input_ids = batch['input_ids']\n      attention_mask = batch['attention_mask']\n      targets = batch['targets']\n      logits = self.forward(input_ids,attention_mask)\n      preds = torch.argmax(logits,dim=1)\n      acc = (preds == targets).sum()/len(targets)\n      loss = self.loss_fn(logits,targets)\n      self.log_dict({'val/loss': loss, 'val/acc': acc})\n      return {'val_loss':loss, 'val_accuracy': acc}\n\n  def predict_step(self, batch, batch_idx):\n      input_ids = batch['input_ids']\n      attention_mask = batch['attention_mask']\n      logits = self.forward(input_ids,attention_mask)\n      preds = torch.argmax(logits,dim=1)\n      return logits, preds\n  \n  def configure_optimizers(self):\n      optimizer = torch.optim.Adam(\n          self.parameters(),\n          lr=self.lr,\n          eps=self.adam_eps\n          )\n      \n      scheduler = get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=self.warmup_steps,\n            num_training_steps=self.trainer.estimated_stepping_batches,\n        )\n      scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n      return [optimizer], [scheduler]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-17T20:00:01.669942Z","iopub.execute_input":"2022-12-17T20:00:01.670488Z","iopub.status.idle":"2022-12-17T20:00:01.692303Z","shell.execute_reply.started":"2022-12-17T20:00:01.670450Z","shell.execute_reply":"2022-12-17T20:00:01.691384Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"wandb.init(project=\"TweetSentimentClassifier\", entity=\"tcastigl\", name='bert_base_uncased_unslanged_conti2')\npl.seed_everything(42)\nBATCH_SIZE=256\nTOKENIZER_MAX_LEN=128\nPRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n#tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\ntokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\ndm = TweetDataModule(\n    TweetDataset(train_df,tokenizer, TOKENIZER_MAX_LEN),\n    TweetDataset(val_df,tokenizer, TOKENIZER_MAX_LEN),\n    batch_size=BATCH_SIZE\n  )\nwandb.config.update({'batch_size': BATCH_SIZE,\n                     'dataset':  'big',\n                     'tokenizer_max_len': TOKENIZER_MAX_LEN})\n\nmodel = SentimentClassifier(PRE_TRAINED_MODEL_NAME, weight_decay=.2)\nmodel = SentimentClassifier.load_from_checkpoint('/kaggle/input/notebook9c29aaf992/logs/checkpoints/last.ckpt', weight_decay=.2)\n\nlogger = pl.loggers.WandbLogger(\n    save_dir='logs',\n    project='TweetSentimentClassifier',\n    name='bertweet_try',\n    resume='must'\n)\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(\n    dirpath=Path('logs/', 'checkpoints'),\n    filename=\"best-model-epoch={epoch:02d}\",\n    monitor=\"val/loss\",\n    train_time_interval=timedelta(minutes=120),\n    save_on_train_epoch_end=True,\n    # auto_insert_metric_name=False,\n    save_top_k=1,\n    save_last=True,\n    mode=\"min\",\n)\ntrainer = pl.Trainer(\n    max_time=\"00:07:00:00\",\n    max_epochs=4,\n    logger=logger,\n    callbacks= [checkpoint_callback],\n    log_every_n_steps=10,\n    val_check_interval=5000,\n    enable_progress_bar=True,\n    accelerator='gpu',\n    devices=2,\n    strategy='dp'\n)\nprint(20*'-','starting training', 20*'-')\ntrainer.fit(model, datamodule=dm)\n#wandb.finish()\nprint(20*'-','training done', 20*'-')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-17T20:00:02.383909Z","iopub.execute_input":"2022-12-17T20:00:02.384296Z","iopub.status.idle":"2022-12-17T20:00:41.170624Z","shell.execute_reply.started":"2022-12-17T20:00:02.384255Z","shell.execute_reply":"2022-12-17T20:00:41.167248Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtcastigl\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20221217_200003-lozlw12v</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/tcastigl/TweetSentimentClassifier/runs/lozlw12v\" target=\"_blank\">bert_base_uncased_unslanged_conti</a></strong> to <a href=\"https://wandb.ai/tcastigl/TweetSentimentClassifier\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e10414a2800d441f805275604d34ef5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75d4ec93487c4f3fa3937744c8ee5431"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3883170fca2348cf98e6def84e45244e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"793d64bd85c64142aea84fb7bd99caa2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b72b1448b2c4409bbbfa0b0ae6beec0"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1918285563.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPRE_TRAINED_MODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/bertClassifier-ckpt/last.ckpt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m logger = pl.loggers.WandbLogger(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/core/saving.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mhparams_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         )\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/core/saving.py\u001b[0m in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpl_legacy_patch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhparams_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/cloud_io.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1038\u001b[0m                 \u001b[0mautocommit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mac\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m                 \u001b[0mcache_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m             )\n\u001b[1;32m   1042\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_mkdir\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mLocalFileOpener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtouch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocommit\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                     \u001b[0mcompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/bertClassifier-ckpt/last.ckpt'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/bertClassifier-ckpt/last.ckpt'","output_type":"error"}]},{"cell_type":"code","source":"print(20*'-','loading test data', 20*'-')\ntest_df = pd.read_table(BASE_PATH / \"test_data.txt\", header=None, dtype=str, names=['tweet'], on_bad_lines='skip')\nfor i, tweet in enumerate(test_df.tweet):\n  test_df.loc[i, 'tweet'] = ''.join(tweet.split(',')[1:])\nprint(20*'-','preprocessing test data', 20*'-')\n# Processing\n#test_df['tweet'] = test_df['tweet'].apply(lambda x: hlp.remove_stopwords(x))\n#test_df['tweet'] = test_df['tweet'].apply(lambda x: hlp.remove_punct(x))\ntest_df['tweet'] = test_df['tweet'].apply(lambda x: hlp.add_space(x))\ntest_df['tweet'] = test_df['tweet'].apply(lambda x: hlp.remove_white_space(x))\n#test_df['tweet'] = test_df['tweet'].apply(lambda x: hlp.remove_words_digits(x))\ntest_df['tweet'] = test_df['tweet'].apply(lambda x: hlp.to_lower(x))\n#test_df['tweet'] = test_df['tweet'].apply(lambda x: hlp.remove_specific_words(x))\ntest_df['tweet'] = test_df['tweet'].apply(lambda x: hlp.remove_repeating_char(x))\ntest_df['tweet'] = test_df['tweet'].apply(lambda x: hlp.lemmatize(x))\ntest_df.shape","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-10T15:24:01.874702Z","iopub.execute_input":"2022-12-10T15:24:01.875441Z","iopub.status.idle":"2022-12-10T15:24:03.295771Z","shell.execute_reply.started":"2022-12-10T15:24:01.875398Z","shell.execute_reply":"2022-12-10T15:24:03.294539Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"-------------------- loading test data --------------------\n-------------------- preprocessing test data --------------------\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(10000, 1)"},"metadata":{}}]},{"cell_type":"code","source":"class TweetTestDataset(Dataset):\n  def __init__(self,tweets_df, tokenizer, max_len):\n    super().__init__()\n    self.tweets = tweets_df.tweet.to_numpy()\n    self.tokenizer = tokenizer\n    self.max_len = max_len\n  \n  def __len__(self):\n    return len(self.tweets)\n  \n  def __getitem__(self, item):\n    tweets = str(self.tweets[item])\n    encoding = self.tokenizer.encode_plus(\n      tweets,\n      add_special_tokens=True,\n      max_length=self.max_len,\n      return_token_type_ids=False,\n      pad_to_max_length=True,\n      return_attention_mask=True,\n      return_tensors='pt',\n    )\n    return {\n      'tweet_text': tweets,\n      'input_ids': encoding['input_ids'].flatten(),\n      'attention_mask': encoding['attention_mask'].flatten(),\n    }","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-10T15:24:03.297446Z","iopub.execute_input":"2022-12-10T15:24:03.298086Z","iopub.status.idle":"2022-12-10T15:24:03.309280Z","shell.execute_reply.started":"2022-12-10T15:24:03.298048Z","shell.execute_reply":"2022-12-10T15:24:03.308184Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\n#BATCH_SIZE=128\n#TOKENIZER_MAX_LEN=128\n#PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n#tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n#test_dataloader = DataLoader(TweetTestDataset(test_df,tokenizer, TOKENIZER_MAX_LEN))\n#model = SentimentClassifier.load_from_checkpoint('/kaggle/input/bertclassifiertrained/last (1).ckpt')\n'''\nlogger = pl.loggers.WandbLogger(\n    save_dir='logs',\n    project='bertClassifier',\n    name='try',\n)\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(\n    dirpath=Path('logs/', 'checkpoints'),\n    filename=\"best-model-epoch={epoch:02d}\",\n    monitor=\"val/loss\",\n    train_time_interval=timedelta(minutes=120),\n    save_on_train_epoch_end=True,\n    # auto_insert_metric_name=False,\n    save_top_k=1,\n    save_last=True,\n    mode=\"min\",\n)\ntrainer = pl.Trainer(\n    max_time=\"00:12:00:00\",\n    max_epochs=2,\n    callbacks= [checkpoint_callback],\n    log_every_n_steps=50,\n    val_check_interval=5000,\n    enable_progress_bar=True,\n    accelerator='gpu',\n    devices=2,\n    strategy='dp'\n)\n\nwandb.init(project=\"TweetSentimentClassifier\", entity=\"tcastigl\", name='testing_big_dataset_freeze_bert')\n'''\nprint(20*'-','computing and saving predictions', 20*'-')\ntest_dataloader = DataLoader(TweetTestDataset(test_df,tokenizer, TOKENIZER_MAX_LEN))\npreds = trainer.predict(model, test_dataloader)\n\ntest_preds = np.array([int(preds[i][1]) for i in range(len(preds))])\ntest_preds[test_preds == 0] = -1\ntest_preds = pd.DataFrame(test_preds)\ntest_preds.index += 1\ntest_preds.to_csv('test_preds_try.csv',header='Prediction')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-10T15:24:03.311288Z","iopub.execute_input":"2022-12-10T15:24:03.312553Z","iopub.status.idle":"2022-12-10T15:29:01.061901Z","shell.execute_reply.started":"2022-12-10T15:24:03.312513Z","shell.execute_reply":"2022-12-10T15:29:01.060924Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"-------------------- computing and saving predictions --------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting: 106it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f290d51d2d54810a7b6e591201af49a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"}]}]}